# MediaPipe Multi-Modal Detection System

## A Professional, Production-Ready System for Real-Time Computer Vision Analysis

![Python](https://img.shields.io/badge/python-3.8%2B-blue)
![MediaPipe](https://img.shields.io/badge/mediapipe-0.10%2B-green)
![OpenCV](https://img.shields.io/badge/opencv-4.8%2B-red)
![License](https://img.shields.io/badge/license-MIT-yellow)

<!-- Option 1: Use local file (must be committed) -->
![Header](header.png)

<!-- Option 2: Use external URL (no commit needed) -->
<!-- ![Header](https://your-image-hosting-service.com/header.png) -->

<!-- Option 3: Create an assets folder (recommended) -->
<!-- ![Header](assets/images/header.png) -->

---

## ğŸ¯ Overview

An advanced multi-modal detection system integrating:
- **Face Detection & Emotion Recognition** - 7 emotions with 468 facial landmarks
- **Hand Tracking & Gesture Recognition** - 8+ gestures with 21 hand landmarks
- **Pose Estimation & Posture Analysis** - Full body with 33 pose landmarks
- **Object Detection** - 80+ objects from COCO dataset
- **Contextual Analysis** - Intelligent interpretation combining all modalities

## âœ¨ Key Features

### Core Detection
- âœ… Real-time face mesh detection with 468 landmarks
- âœ… Emotion recognition using DeepFace (happy, sad, angry, fear, surprise, disgust, neutral)
- âœ… Hand tracking with 21 landmarks per hand (supports 2 hands)
- âœ… Gesture recognition (Thumbs Up, Peace, OK, Fist, Open Hand, Pointing, Rock)
- âœ… Full body pose estimation with 33 landmarks
- âœ… Posture analysis (upright, slouching, tilted, forward head, neutral)
- âœ… Object detection supporting 80+ categories

### Professional Features
- ğŸ“Š **Real-time Performance Monitoring** - FPS tracking and detailed metrics
- ğŸ¯ **Contextual Analysis** - Intelligent interpretation (e.g., "Tech Frustration", "Positive Feedback")
- âš™ï¸ **Modular Architecture** - Clean separation of concerns
- ğŸ“ **Comprehensive Logging** - Color-coded console + file logging
- ğŸ”§ **Centralized Configuration** - Easy customization via config files
- ğŸ›¡ï¸ **Robust Error Handling** - Graceful degradation
- ğŸ’¾ **Frame Capture** - Save annotated frames with timestamp
- ğŸ¨ **Beautiful UI** - Modern gradient overlays with status indicators

## ğŸ“ Project Structure

```
Detection_MediaPipe_/
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/                 # Core functionality
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py         # Configuration management
â”‚   â”‚   â”œâ”€â”€ logger.py         # Logging system
â”‚   â”‚   â””â”€â”€ performance.py    # Performance monitoring
â”‚   â”œâ”€â”€ detectors/            # Detection modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py           # Base detector class
â”‚   â”‚   â”œâ”€â”€ emotion.py        # Emotion detection (DeepFace)
â”‚   â”‚   â”œâ”€â”€ gesture.py        # Gesture recognition
â”‚   â”‚   â”œâ”€â”€ posture.py        # Posture analysis
â”‚   â”‚   â””â”€â”€ context.py        # Context analysis
â”‚   â”œâ”€â”€ visualization/        # Rendering
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ renderer.py       # Visualization renderer
â”‚   â””â”€â”€ system.py             # Main system orchestrator
â”œâ”€â”€ models/                   # MediaPipe models (downloaded)
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ face_landmarker.task
â”‚   â”œâ”€â”€ hand_landmarker.task
â”‚   â”œâ”€â”€ pose_landmarker_lite.task
â”‚   â””â”€â”€ efficientdet_lite0.tflite
â”œâ”€â”€ tests/                    # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_detectors.py
â”œâ”€â”€ scripts/                  # Utility scripts
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ download_models.py    # Auto-download models
â”‚   â””â”€â”€ check_models.py       # Verify model files
â”œâ”€â”€ output/                   # Generated output
â”‚   â”œâ”€â”€ logs/                 # Application logs
â”‚   â”œâ”€â”€ frames/               # Saved frames
â”‚   â””â”€â”€ videos/               # Saved videos
â”œâ”€â”€ docs/                     # Documentation
â”‚   â””â”€â”€ user_guide.md
â”œâ”€â”€ app.py                    # Main entry point
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ setup.py                  # Package configuration
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                 # This file
```

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.8+** ([Download](https://www.python.org/downloads/))
- **Webcam/Camera**
- **macOS, Linux, or Windows**

### Installation

#### Option 1: Standard Installation (Recommended)

```bash
# 1. Navigate to project directory
cd /Users/ahmedziada/Documents/Route/Detection_MediaPipe_

# 2. Create virtual environment
python3 -m venv venv

# 3. Activate virtual environment
source venv/bin/activate          # macOS/Linux
# OR
venv\Scripts\activate             # Windows

# 4. Install dependencies
pip install -r requirements.txt

# 5. Download MediaPipe models
python scripts/download_models.py

# 6. Run the application
python app.py
```

#### Option 2: Package Installation (Advanced)

```bash
# Install as a package (editable mode for development)
pip install -e .

# Run from anywhere
mediapipe-detect
```

### First Run

On first run, the system will:
1. âœ… Validate all model files exist
2. âœ… Load 4 MediaPipe models (~25 MB total)
3. âœ… Initialize camera (10-frame warmup)
4. âœ… Start real-time detection at 1280x720 resolution

## ğŸ® Usage

### Keyboard Controls

| Key | Action |
|-----|--------|
| `Q` | Quit application |
| `S` | Save current frame with timestamp |
| `1` | Toggle face detection & emotion analysis |
| `2` | Toggle hand detection & gesture recognition |
| `3` | Toggle pose detection & posture analysis |
| `4` | Toggle object detection |
| `R` | Show detailed performance report |

### Display Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [LEFT PANEL]            [VIDEO FEED]      [PERF PANEL]     â”‚
â”‚  â€¢ Emotion Info                             â€¢ FPS: 30.2     â”‚
â”‚  â€¢ Confidence Bar                           â€¢ Frame: 1234   â”‚
â”‚  â€¢ Top 3 Emotions                           â€¢ Time: 33ms    â”‚
â”‚  â€¢ Gestures                                                 â”‚
â”‚  â€¢ Posture                                                  â”‚
â”‚  â€¢ Objects                                                  â”‚
â”‚  â€¢ Context Analysis                                         â”‚
â”‚                                                              â”‚
â”‚  [STATUS BAR: Face ON | Hands ON | Pose ON | Objects ON]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration

Edit `src/core/config.py` to customize:

```python
# Camera Settings
@dataclass
class CameraConfig:
    index: int = 1              # Camera index (0, 1, 2...)
    width: int = 1280           # Resolution width
    height: int = 720           # Resolution height
    fps: int = 30               # Target FPS

# Processing Settings
@dataclass
class ProcessingConfig:
    emotion_frame_skip: int = 10   # Analyze emotion every N frames
    max_detection_faces: int = 1   # Max faces to detect
    max_detection_hands: int = 2   # Max hands to detect

# Detection Thresholds
@dataclass
class DetectionThresholds:
    object_confidence: float = 0.5  # Object detection threshold (0.0-1.0)
```

## ğŸ“Š Performance

| Metric | Value | Hardware |
|--------|-------|----------|
| **FPS** | 25-35 | MacBook Air M1 |
| **Latency** | <40ms | MacBook Air M1 |
| **Memory** | ~500MB-1GB | During operation |
| **CPU** | 40-60% | Single core usage |

### Optimization Tips

**For Higher FPS:**
```python
# 1. Increase emotion analysis interval
processing_config.emotion_frame_skip = 20  # Analyze less frequently

# 2. Disable unused detectors
# Press 1, 2, 3, or 4 during runtime

# 3. Lower resolution (in config.py)
camera_config.width = 640
camera_config.height = 480
```

**For Better Accuracy:**
```python
# Lower detection thresholds
detection_thresholds.object_confidence = 0.3  # Detect more objects
```

## ğŸ¯ Detection Capabilities

### Emotions (7 Categories)
- Happy, Sad, Angry, Fear, Surprise, Disgust, Neutral
- Real-time confidence scores
- Emotion history tracking

### Gestures (8+ Types)
- ğŸ‘ Thumbs Up / ğŸ‘ Thumbs Down
- âœŒï¸ Peace Sign
- ğŸ‘Œ OK Sign
- âœ‹ Open Hand
- âœŠ Fist
- â˜ï¸ Pointing
- ğŸ¤˜ Rock Sign

### Postures (5 Types)
- Upright & Confident
- Slouching
- Tilted/Asymmetric
- Forward Head Posture
- Neutral Posture

### Context Patterns (8+ Scenarios)
- `[+]` Positive Feedback (happy + thumbs up)
- `[!]` Tech Frustration (frustrated + laptop detected)
- `[~]` Tired/Stressed (sad + slouching)
- `[*]` Appears Focused (neutral + upright posture)
- `[=]` Peaceful/Relaxed (happy + peace sign)
- `[^]` Excited/Enthusiastic
- `[>]` Presenting/Speaking
- `[#]` Working/Concentrating

## ğŸ”§ Troubleshooting

### Issue: Camera Not Found
```python
# Solution 1: Try different camera index
camera_config.index = 0  # Try 0, 1, 2...

# Solution 2: List available cameras
python -c "import cv2; [print(f'Camera {i}') for i in range(10) if cv2.VideoCapture(i).isOpened()]"
```

### Issue: Models Not Loading
```bash
# Re-download models
python scripts/download_models.py

# Verify models exist
python scripts/check_models.py

# Check model directory
ls -la models/
```

### Issue: Low FPS (<15)
```python
# Quick fixes:
# 1. Increase emotion skip
processing_config.emotion_frame_skip = 20

# 2. Lower resolution
camera_config.width = 640
camera_config.height = 480

# 3. Disable pose detection (press 3)
# 4. Close other applications
```

### Issue: Import Errors
```bash
# Reinstall dependencies
pip install --upgrade -r requirements.txt

# Or install as package
pip install -e .
```

### Issue: DeepFace Errors
```bash
# Update DeepFace
pip install --upgrade deepface tensorflow

# Verify installation
python -c "from deepface import DeepFace; print('OK')"
```

## ğŸ“š Documentation

- **[User Guide](docs/user_guide.md)** - Comprehensive usage guide
- **[API Reference](docs/api_reference.md)** - Code documentation
- **[Models README](models/README.md)** - Model information

## ğŸ§ª Testing

```bash
# Run unit tests
python -m pytest tests/ -v

# Run with coverage
python -m pytest tests/ --cov=src --cov-report=html

# Test specific module
python -m pytest tests/test_detectors.py -v
```

## ğŸ“¦ What is `setup.py`?

`setup.py` makes your project installable as a Python package:

**Benefits:**
- âœ… Install with `pip install .`
- âœ… Create command-line tools (`mediapipe-detect`)
- âœ… Clean imports without path hacks
- âœ… Distribute to PyPI
- âœ… Development mode: `pip install -e .`

**Usage:**
```bash
# Install in development mode (changes reflect immediately)
pip install -e .

# Run from anywhere after installation
mediapipe-detect

# Or import in other projects
from src.detectors import EmotionAnalyzer
```

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:
- ğŸ¯ Additional gesture recognition patterns
- ğŸ§  More emotion models (age, gender)
- ğŸƒ Activity recognition (walking, running, sitting)
- ğŸ‘¥ Multi-person tracking
- ğŸš€ GPU acceleration (CUDA support)
- ğŸ¥ Video file processing
- ğŸ“Š Data export (CSV, JSON)

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) file for details

## ğŸ™ Acknowledgments

- **[MediaPipe](https://developers.google.com/mediapipe)** by Google - Computer vision framework
- **[DeepFace](https://github.com/serengil/deepface)** by Sefik Ilkin Serengil - Facial analysis
- **[OpenCV](https://opencv.org/)** - Computer vision library
- **Community** - Open source contributors

## ğŸ“§ Support

- ğŸ’¬ **Issues**: [GitHub Issues](https://github.com/ahmedaliziada/mediapipe-detection/issues)
- ğŸ“§ **Email**: ahmedaliziada@outlook.com
- ğŸ“– **Docs**: [Documentation](docs/)

## ğŸ”— Links

- [MediaPipe Solutions](https://developers.google.com/mediapipe/solutions)
- [DeepFace GitHub](https://github.com/serengil/deepface)
- [OpenCV Tutorials](https://docs.opencv.org/master/d9/df8/tutorial_root.html)

---

<div align="center">

**Version 2.0.0** | **Last Updated: 2024**

Made with â¤ï¸ using MediaPipe, OpenCV, and Python

[â¬† Back to Top](#mediapipe-multi-modal-detection-system)

</div>
